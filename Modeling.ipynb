{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mP3AVyGiUwNa"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-lightning"
      ],
      "metadata": {
        "id": "ja2WvC90aQ6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "id": "5d27n0YVaSQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kss"
      ],
      "metadata": {
        "id": "NDgio28waTSl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "\n",
        "from transformers import BertModel, BertTokenizer, AdamW, PreTrainedTokenizerFast, BartModel\n",
        "\n",
        "from torch.nn.init import xavier_uniform_\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "import kss\n",
        "import re     "
      ],
      "metadata": {
        "id": "R1gQyDn-aUWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = PreTrainedTokenizerFast.from_pretrained('gogamza/kobart-base-v1')"
      ],
      "metadata": {
        "id": "-qKCpqTPaXt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Class"
      ],
      "metadata": {
        "id": "hJgNmKVIaf_g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SummDataset(Dataset):\n",
        "\n",
        "    def __init__(\n",
        "        self, \n",
        "        data: pd.DataFrame, \n",
        "        tokenizer: PreTrainedTokenizerFast, \n",
        "        max_token_len: int = 512\n",
        "    ):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = data\n",
        "        self.max_token_len = max_token_len\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index: int):\n",
        "        data_row = self.data.iloc[index]\n",
        "\n",
        "        tokenlist = []\n",
        "        for sent in data_row.article_original:\n",
        "            tokenlist.append(tokenizer(\n",
        "                text = sent,\n",
        "                add_special_tokens = True)) #, # Add '[CLS]' and '[SEP]'\n",
        "    \n",
        "        src = [] # 토크나이징 된 전체 문단\n",
        "        labels = []  # 요약문에 해당하면 1, 아니면 0으로 문장수 만큼 생성\n",
        "        segs = []  #각 토큰에 대해 홀수번째 문장이면 0, 짝수번째 문장이면 1을 매핑\n",
        "        clss = []  #[CLS]토큰의 포지션값을 지정\n",
        "\n",
        "        odd = 0\n",
        "        for tkns in tokenlist:\n",
        "            if odd > 1 : odd = 0\n",
        "            clss = clss + [len(src)]\n",
        "            src = src + tkns['input_ids']\n",
        "            segs = segs + [odd] * len(tkns['input_ids'])\n",
        "            if tokenlist.index(tkns) in data_row.extractive :\n",
        "                labels = labels + [1]\n",
        "            else:\n",
        "                labels = labels + [0]\n",
        "            odd += 1\n",
        "        \n",
        "            #truncation\n",
        "            if len(src) == MAX_TOKEN_COUNT:\n",
        "                break\n",
        "            elif len(src) > MAX_TOKEN_COUNT:\n",
        "                src = src[:self.max_token_len - 1] + [src[-1]]\n",
        "                segs = segs[:self.max_token_len]\n",
        "                break\n",
        "    \n",
        "        #padding\n",
        "        if len(src) < MAX_TOKEN_COUNT:\n",
        "            src = src + [0]*(self.max_token_len - len(src))\n",
        "            segs = segs + [0]*(self.max_token_len - len(segs))\n",
        "            \n",
        "        if len(clss) < MAX_TOKEN_COUNT:\n",
        "            clss = clss + [-1]*(self.max_token_len - len(clss))\n",
        "        if len(labels) < MAX_TOKEN_COUNT:\n",
        "            labels = labels + [0]*(self.max_token_len - len(labels))\n",
        "\n",
        "        return dict(\n",
        "            src = torch.tensor(src),\n",
        "            segs = torch.tensor(segs),\n",
        "            clss = torch.tensor(clss),\n",
        "            labels= torch.FloatTensor(labels)\n",
        "        )"
      ],
      "metadata": {
        "id": "M-x-bZMpaZ08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, dropout, dim, max_len=5000):\n",
        "        pe = torch.zeros(max_len, dim)\n",
        "        position = torch.arange(0, max_len).unsqueeze(1)\n",
        "        div_term = torch.exp((torch.arange(0, dim, 2, dtype=torch.float) *\n",
        "                              -(math.log(10000.0) / dim)))\n",
        "        pe[:, 0::2] = torch.sin(position.float() * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position.float() * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.register_buffer('pe', pe)\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        self.dim = dim\n",
        "\n",
        "    def forward(self, emb, step=None):\n",
        "        emb = emb * math.sqrt(self.dim)\n",
        "        if (step):\n",
        "            emb = emb + self.pe[:, step][:, None, :]\n",
        "\n",
        "        else:\n",
        "            emb = emb + self.pe[:, :emb.size(1)]\n",
        "        emb = self.dropout(emb)\n",
        "        return emb\n",
        "\n",
        "    def get_emb(self, emb):\n",
        "        return self.pe[:, :emb.size(1)]"
      ],
      "metadata": {
        "id": "tMbpamkeaZyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, heads, d_ff, dropout):\n",
        "        super(TransformerEncoderLayer, self).__init__()\n",
        "\n",
        "        self.self_attn = MultiHeadedAttention(\n",
        "            heads, d_model, dropout=dropout)\n",
        "        self.feed_forward = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
        "        self.layer_norm = nn.LayerNorm(d_model, eps=1e-6) \n",
        "        self.dropout = nn.Dropout(dropout) \n",
        "\n",
        "    def forward(self, iter, query, inputs, mask):\n",
        "        if (iter != 0):\n",
        "            input_norm = self.layer_norm(inputs)\n",
        "        else:\n",
        "            input_norm = inputs\n",
        "\n",
        "        mask = mask.unsqueeze(1)\n",
        "        context = self.self_attn(input_norm, input_norm, input_norm,\n",
        "                                 mask=mask)\n",
        "        out = self.dropout(context) + inputs\n",
        "        return self.feed_forward(out)"
      ],
      "metadata": {
        "id": "4uW-EvVsaZwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ExtTransformerEncoder(nn.Module):\n",
        "    def __init__(self, hidden_size=768, d_ff=2048, heads=8, dropout=0.3, num_inter_layers=2): \n",
        "        super(ExtTransformerEncoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_inter_layers = num_inter_layers\n",
        "        self.pos_emb = PositionalEncoding(dropout, hidden_size)\n",
        "        self.transformer_inter = nn.ModuleList(\n",
        "            [TransformerEncoderLayer(hidden_size, heads, d_ff, dropout)\n",
        "            for _ in range(num_inter_layers)])\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.layer_norm = nn.LayerNorm(hidden_size, eps=1e-6)\n",
        "        self.wo = nn.Linear(hidden_size, 1, bias=True)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, top_vecs, mask):\n",
        "        \"\"\" See :obj:`EncoderBase.forward()`\"\"\"\n",
        "\n",
        "        batch_size, n_sents = top_vecs.size(0), top_vecs.size(1)\n",
        "        pos_emb = self.pos_emb.pe[:, :n_sents]\n",
        "        x = top_vecs * mask[:, :, None].float()\n",
        "        x = x + pos_emb\n",
        "\n",
        "        for i in range(self.num_inter_layers):\n",
        "            x = self.transformer_inter[i](i, x, x, ~mask) \n",
        "\n",
        "        x = self.layer_norm(x)\n",
        "        sent_scores = self.sigmoid(self.wo(x))\n",
        "        sent_scores = sent_scores.squeeze(-1) * mask.float()\n",
        "\n",
        "        return sent_scores"
      ],
      "metadata": {
        "id": "1S4y1walaZtr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionwiseFeedForward(nn.Module):\n",
        "    \"\"\" A two-layer Feed-Forward-Network with residual layer norm.\n",
        "\n",
        "    Args:\n",
        "        d_model (int): the size of input for the first-layer of the FFN.\n",
        "        d_ff (int): the hidden layer size of the second-layer\n",
        "            of the FNN.\n",
        "        dropout (float): dropout probability in :math:`[0, 1)`.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
        "        super(PositionwiseFeedForward, self).__init__()\n",
        "        self.w_1 = nn.Linear(d_model, d_ff)\n",
        "        self.w_2 = nn.Linear(d_ff, d_model)\n",
        "        self.layer_norm = nn.LayerNorm(d_model, eps=1e-6)\n",
        "        self.dropout_1 = nn.Dropout(dropout)\n",
        "        self.dropout_2 = nn.Dropout(dropout)\n",
        "        \n",
        "    def gelu(self, x):\n",
        "        return 0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        inter = self.dropout_1(self.gelu(self.w_1(self.layer_norm(x))))\n",
        "        output = self.dropout_2(self.w_2(inter))\n",
        "        return output + x"
      ],
      "metadata": {
        "id": "4nxPSRI6aZrO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadedAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "       head_count (int): number of parallel heads\n",
        "       model_dim (int): the dimension of keys/values/queries,\n",
        "           must be divisible by head_count\n",
        "       dropout (float): dropout parameter\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, head_count, model_dim, dropout=0.1, use_final_linear=True):\n",
        "        assert model_dim % head_count == 0\n",
        "        self.dim_per_head = model_dim // head_count\n",
        "        self.model_dim = model_dim\n",
        "\n",
        "        super(MultiHeadedAttention, self).__init__()\n",
        "        self.head_count = head_count\n",
        "\n",
        "        self.linear_keys = nn.Linear(model_dim,\n",
        "                                     head_count * self.dim_per_head)\n",
        "        self.linear_values = nn.Linear(model_dim,\n",
        "                                       head_count * self.dim_per_head)\n",
        "        self.linear_query = nn.Linear(model_dim,\n",
        "                                      head_count * self.dim_per_head)\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.use_final_linear = use_final_linear\n",
        "        if (self.use_final_linear):\n",
        "            self.final_linear = nn.Linear(model_dim, model_dim)\n",
        "    def forward(self, key, value, query, mask=None,\n",
        "                layer_cache=None, type=None, predefined_graph_1=None):\n",
        "\n",
        "        batch_size = key.size(0)\n",
        "        dim_per_head = self.dim_per_head\n",
        "        head_count = self.head_count\n",
        "        key_len = key.size(1)\n",
        "        query_len = query.size(1)\n",
        "\n",
        "        def shape(x):\n",
        "            \"\"\"  projection \"\"\"\n",
        "            return x.view(batch_size, -1, head_count, dim_per_head) \\\n",
        "                .transpose(1, 2)\n",
        "        def unshape(x):\n",
        "            \"\"\"  compute context \"\"\"\n",
        "            return x.transpose(1, 2).contiguous() \\\n",
        "                .view(batch_size, -1, head_count * dim_per_head)\n",
        "\n",
        "        # 1) Project key, value, and query.\n",
        "        if layer_cache is not None:\n",
        "            if type == \"self\":\n",
        "                query, key, value = self.linear_query(query), \\\n",
        "                                    self.linear_keys(query), \\\n",
        "                                    self.linear_values(query)\n",
        "\n",
        "                key = shape(key)\n",
        "                value = shape(value)\n",
        "\n",
        "                if layer_cache is not None:\n",
        "                    device = key.device\n",
        "                    if layer_cache[\"self_keys\"] is not None:\n",
        "                        key = torch.cat(\n",
        "                            (layer_cache[\"self_keys\"].to(device), key),\n",
        "                            dim=2)\n",
        "                    if layer_cache[\"self_values\"] is not None:\n",
        "                        value = torch.cat(\n",
        "                            (layer_cache[\"self_values\"].to(device), value),\n",
        "                            dim=2)\n",
        "                    layer_cache[\"self_keys\"] = key\n",
        "                    layer_cache[\"self_values\"] = value\n",
        "            elif type == \"context\":\n",
        "                query = self.linear_query(query)\n",
        "                if layer_cache is not None:\n",
        "                    if layer_cache[\"memory_keys\"] is None:\n",
        "                        key, value = self.linear_keys(key), \\\n",
        "                                     self.linear_values(value)\n",
        "                        key = shape(key)\n",
        "                        value = shape(value)\n",
        "                    else:\n",
        "                        key, value = layer_cache[\"memory_keys\"], \\\n",
        "                                     layer_cache[\"memory_values\"]\n",
        "                    layer_cache[\"memory_keys\"] = key\n",
        "                    layer_cache[\"memory_values\"] = value\n",
        "                else:\n",
        "                    key, value = self.linear_keys(key), \\\n",
        "                                 self.linear_values(value)\n",
        "                    key = shape(key)\n",
        "                    value = shape(value)\n",
        "        else:\n",
        "            key = self.linear_keys(key)\n",
        "            value = self.linear_values(value)\n",
        "            query = self.linear_query(query)\n",
        "            key = shape(key)\n",
        "            value = shape(value)\n",
        "\n",
        "        query = shape(query)\n",
        "\n",
        "        key_len = key.size(2)\n",
        "        query_len = query.size(2)\n",
        "\n",
        "        # 2) Calculate and scale scores.\n",
        "        query = query / math.sqrt(dim_per_head)\n",
        "        scores = torch.matmul(query, key.transpose(2, 3))\n",
        "\n",
        "        if mask is not None:\n",
        "            mask = mask.unsqueeze(1).expand_as(scores)\n",
        "            scores = scores.masked_fill(mask, -1e18) # how can i fix it to use fp16...\n",
        "\n",
        "        # 3) Apply attention dropout and compute context vectors.\n",
        "\n",
        "        attn = self.softmax(scores)\n",
        "\n",
        "        if (not predefined_graph_1 is None):\n",
        "            attn_masked = attn[:, -1] * predefined_graph_1\n",
        "            attn_masked = attn_masked / (torch.sum(attn_masked, 2).unsqueeze(2) + 1e-9)\n",
        "\n",
        "            attn = torch.cat([attn[:, :-1], attn_masked.unsqueeze(1)], 1)\n",
        "\n",
        "        drop_attn = self.dropout(attn)\n",
        "        if (self.use_final_linear):\n",
        "            context = unshape(torch.matmul(drop_attn, value))\n",
        "            output = self.final_linear(context)\n",
        "            return output\n",
        "        else:\n",
        "            context = torch.matmul(drop_attn, value)\n",
        "            return context"
      ],
      "metadata": {
        "id": "qGVOpTVTaZox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Summarizer(pl.LightningModule): #\n",
        "\n",
        "    def __init__(self, n_training_steps=None, n_warmup_steps=None):\n",
        "        super().__init__()\n",
        "        self.max_pos = 512\n",
        "        self.bert = BertModel.from_pretrained('gogamza/kobart-base-v1') #, return_dict=True)\n",
        "        self.ext_layer = ExtTransformerEncoder()\n",
        "        self.n_training_steps = n_training_steps\n",
        "        self.n_warmup_steps = n_warmup_steps\n",
        "        self.loss = nn.BCELoss(reduction='none')\n",
        "    \n",
        "        for p in self.ext_layer.parameters():\n",
        "            if p.dim() > 1:\n",
        "                xavier_uniform_(p)\n",
        "\n",
        "    def forward(self, src, segs, clss, labels=None): #, input_ids, attention_mask, labels=None):\n",
        "        \n",
        "        mask_src = ~(src == 0) #1 - (src == 0)\n",
        "        mask_cls = ~(clss == -1) #1 - (clss == -1)\n",
        "\n",
        "        top_vec = self.bert(src, token_type_ids=segs, attention_mask=mask_src)\n",
        "        top_vec = top_vec.last_hidden_state\n",
        "        \n",
        "        sents_vec = top_vec[torch.arange(top_vec.size(0)).unsqueeze(1), clss]\n",
        "        sents_vec = sents_vec * mask_cls[:, :, None].float()\n",
        "\n",
        "        sent_scores = self.ext_layer(sents_vec, mask_cls).squeeze(-1)\n",
        "        \n",
        "        loss = 0\n",
        "        if labels is not None:\n",
        "            loss = self.loss(sent_scores, labels)\n",
        "            \n",
        "            loss = (loss * mask_cls.float()).sum() / len(labels)\n",
        "        \n",
        "        return loss, sent_scores\n",
        "\n",
        "    def step(self, batch):\n",
        "\n",
        "        src = batch['src']\n",
        "        if len(batch['labels']) > 0 :\n",
        "            labels = batch['labels']\n",
        "        else:\n",
        "            labels = None\n",
        "        segs = batch['segs']\n",
        "        clss = batch['clss']\n",
        "        \n",
        "        loss, sent_scores = self(src, segs, clss, labels)    \n",
        "        \n",
        "        return loss, sent_scores, labels"
      ],
      "metadata": {
        "id": "nsPhGp6saZmU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "bG6eaUrBaZGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 저장된 모델 불러오기\n",
        "trained_model = torch.load('/content/drive/MyDrive/model_fulldata2.pt') "
      ],
      "metadata": {
        "id": "LmDj4-zLa6XU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#요약하기"
      ],
      "metadata": {
        "id": "r3faJ3flbC0a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 불러오기\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/2022-08-23(1).csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "NDh288oJa6Uz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_TOKEN_COUNT = 512\n",
        "N_EPOCHS = 3\n",
        "BATCH_SIZE = 2"
      ],
      "metadata": {
        "id": "EGsLSibNa6SW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_process(text):\n",
        "    # 문장 분리 하고,\n",
        "    text = re.sub('\n",
        "|\\s-\\s.*', '', text)\n",
        "    sents = kss.split_sentences(text)\n",
        "    \n",
        "    #데이터 가공하고,\n",
        "    tokenlist = []\n",
        "    for sent in sents:\n",
        "        tokenlist.append(tokenizer(\n",
        "            text = sent,\n",
        "            add_special_tokens = True)) #, # Add '[CLS]' and '[SEP]'\n",
        "\n",
        "    src = [] # 토크나이징 된 전체 문단\n",
        "    labels = []  # 요약문에 해당하면 1, 아니면 0으로 문장수 만큼 생성\n",
        "    segs = []  #각 토큰에 대해 홀수번째 문장이면 0, 짝수번째 문장이면 1을 매핑\n",
        "    clss = []  #[CLS]토큰의 포지션값을 지정\n",
        "\n",
        "    odd = 0\n",
        "\n",
        "    for tkns in tokenlist:\n",
        "\n",
        "        if odd > 1 : odd = 0\n",
        "        clss = clss + [len(src)]\n",
        "        src = src + tkns['input_ids']\n",
        "        segs = segs + [odd] * len(tkns['input_ids'])\n",
        "        odd += 1\n",
        "\n",
        "        #truncation\n",
        "        if len(src) == MAX_TOKEN_COUNT:\n",
        "            break\n",
        "        elif len(src) > MAX_TOKEN_COUNT:\n",
        "            src = src[:MAX_TOKEN_COUNT - 1] + [src[-1]]\n",
        "            segs = segs[:MAX_TOKEN_COUNT]\n",
        "            break\n",
        "\n",
        "    #padding\n",
        "    if len(src) < MAX_TOKEN_COUNT:\n",
        "        src = src + [0]*(MAX_TOKEN_COUNT - len(src))\n",
        "        segs = segs + [0]*(MAX_TOKEN_COUNT - len(segs))\n",
        "\n",
        "    if len(clss) < MAX_TOKEN_COUNT:\n",
        "        clss = clss + [-1]*(MAX_TOKEN_COUNT - len(clss))\n",
        "\n",
        "    return dict(\n",
        "        sents = sents, #정답 출력을 위해...\n",
        "        src = torch.tensor(src),\n",
        "        segs = torch.tensor(segs),\n",
        "        clss = torch.tensor(clss),\n",
        "    )"
      ],
      "metadata": {
        "id": "IF8tRTixa6P4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_test(text):\n",
        "    data = data_process(text.replace('\\n',''))\n",
        "    \n",
        "    #trained_model에 넣어 결과값 반환\n",
        "    _, rtn = trained_model(data['src'].unsqueeze(0), data['segs'].unsqueeze(0), data['clss'].unsqueeze(0))\n",
        "    rtn = rtn.squeeze()\n",
        "    \n",
        "    # 예측 결과값을 받기 위한 프로세스\n",
        "    rtn_sort, idx = rtn.sort(descending = True)\n",
        "    \n",
        "    rtn_sort = rtn_sort.tolist()\n",
        "    idx = idx.tolist()\n",
        "\n",
        "    end_idx = rtn_sort.index(0)\n",
        "\n",
        "    rtn_sort = rtn_sort[:end_idx]\n",
        "    idx = idx[:end_idx]\n",
        "    \n",
        "    if len(idx) > 3:\n",
        "        rslt = idx[:3]\n",
        "    else:\n",
        "        rslt = idx\n",
        "        \n",
        "    summ = []\n",
        "    print(' ')\n",
        "    for i, r in enumerate(rslt):\n",
        "        summ.append(data['sents'][r])\n",
        "        #print(summ[i])\n",
        "\n",
        "    return summ"
      ],
      "metadata": {
        "id": "BHogzo5-a6NM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = []\n",
        "for news_sentence in df['text'].values:\n",
        "    sentence.append(news_sentence)"
      ],
      "metadata": {
        "id": "MBfsXpyUa6Ku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "array = []\n",
        "for i in sentence:\n",
        "  sum_list = summarize_test(i)\n",
        "  sum = \" \".join(sum_list)\n",
        "  array.append(sum)\n",
        "print(array)"
      ],
      "metadata": {
        "id": "F1o5W997a6IS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['추출요약']=array\n",
        "df"
      ],
      "metadata": {
        "id": "XbZJN2i0bXWl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}