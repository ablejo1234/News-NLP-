{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip3 install -q transformers"
      ],
      "metadata": {
        "id": "eNawFRSaQQkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pretraining"
      ],
      "metadata": {
        "id": "-_a-nmkVRGOa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1udLACTTQBQB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from LMkor.examples.bertshared_summarization import Summarize\n",
        "summarize = Summarize('/bertshared-kor-base')"
      ],
      "metadata": {
        "id": "mIf0ttVuQGe9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizerFast, EncoderDecoderModel\n",
        "model_bertshared = EncoderDecoderModel.from_pretrained(\"/bertshared-kor-base\")"
      ],
      "metadata": {
        "id": "RRtLg69-QNvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = '''\n",
        "LG전자가 스마트폰을 담당하는 MC(모바일커뮤니케이션)사업부 분할 및 매각을 위한 법률 자문 업무를 김앤장법률사무소에 맡겼다. MC사업부 매각 작업에 속도가 붙을지 관심이 집중되고 있다.\n",
        "22일 인수합병(M&A)업계에 따르면 LG전자는 최근 MC사업부 분할 후 매각 방안 등을 포괄적으로 검토하기 위해 김앤장을 법률자문사로 선임한 것으로 알려졌다. 회계·실사 자문은 EY한영회계법인에 맡길 가능성이 큰 것으로 전해졌다. 김앤장 등 자문사들은 사업본부를 분할한 뒤 사업양수도나 분할사업부의 지분 매각, 지식재산권(IP) 매각 등을 놓고 검토에 들어간 것으로 알려졌다.\n",
        "업계에서는 LG전자가 MC사업본부를 통매각하기보다는 ‘쪼개기 매각’에 나설 것으로 보고 있다. 스마트폰 선행기술 연구개발(R&D) 등 핵심 기능만 남겨둔 채 매각을 시도할 것으로 관측하고 있다. 앞서 권봉석 LG전자 사장은 사내 메시지를 통해 임직원에게 “현재 모든 가능성을 열어 두고 사업 운영방향을 면밀히 검토하고 있다”고 밝히며 매각 추진을 암시했다. M&A업계 관계자는 “거래가 성사되기도 전에 사업 전면 재검토를 공식화한 것은 상당히 이례적”이라며 “향후 매각이 잘 이뤄지지 않더라도 모바일 사업을 철수하겠다는 배수진을 둔 것으로 보인다”고 설명했다.\n",
        "다만 원매자를 찾기가 쉽지 않을 것이란 전망이 우세하다. LG전자 모바일 사업은 한때 글로벌시장에서 톱5 안에 드는 기술력을 인정받았지만 누적 적자만 5조원에 달하고 있다. 업계에서 평가하는 MC사업부의 가치도 5000억원대에서 수조원대까지 편차가 상당히 크다.\n",
        "상대적으로 해외 원매자들의 인수의사가 더 확실한 것으로 알려지고 있다. 북미사업 등 글로벌 시장 확장을 원하는 후발기업들이 주요 대상이다. 베트남의 빈그룹과 중국 기업 등이 유력하게 거론된다. 증권업계를 중심으로는 스마트 기기를 연결하는 사물인터넷(IoT) 사업을 염두에 둔 구글, 페이스북 같은 미국 정보기술(IT) 기업들도 원매자 후보군으로 꼽고 있다.\n",
        "'''\n",
        "\n",
        "summarize(text)"
      ],
      "metadata": {
        "id": "2pxqwpU9QeuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(summarize(text))"
      ],
      "metadata": {
        "id": "FC8C4kufQhjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = summarize(text)\n",
        "print(a)"
      ],
      "metadata": {
        "id": "c-VGTmsNQiyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "eUyvvMQUQkHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "news23 = pd.read_csv(\"/content/drive/MyDrive/2022-08-23.csv\")"
      ],
      "metadata": {
        "id": "GgIAco8lQlni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "news23.head()"
      ],
      "metadata": {
        "id": "pAURJJrYQmqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(news23)):\n",
        "  passage = news23['text'][i]\n",
        "  print(len(passage))"
      ],
      "metadata": {
        "id": "plK5GCNDQt0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrain_sum = []\n",
        "for i in range(len(news23)):\n",
        "  passage = news23['text'][i]\n",
        "  try:\n",
        "    sum = str(summarize(passage))\n",
        "    pretrain_sum.append(sum)\n",
        "  except :\n",
        "    pretrain_sum.append('')"
      ],
      "metadata": {
        "id": "XeoN0WZjQ_dd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrain_sum[0]"
      ],
      "metadata": {
        "id": "rq45hgU2RB82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dataset"
      ],
      "metadata": {
        "id": "52gZxQQ3RIkA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install datasets"
      ],
      "metadata": {
        "id": "IX0B2F-4RKCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import list_datasets, load_dataset\n",
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "mFR1P8dBROUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "k2sGT7u0RPfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "AK_wk2HPRQF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/train.csv')"
      ],
      "metadata": {
        "id": "CvJ2kDK0RRRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = df['passage']\n",
        "print(len(data))\n",
        "data.head()"
      ],
      "metadata": {
        "id": "iHtF6jKLRWEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary = df['summary']"
      ],
      "metadata": {
        "id": "cqdpRQU0R1BO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "from transformers import BertTokenizerFast, EncoderDecoderModel\n",
        "transformers.logging.set_verbosity_error()"
      ],
      "metadata": {
        "id": "VlT7OklNR26a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer =BertTokenizerFast.from_pretrained(\"/bertshared-kor-base\")"
      ],
      "metadata": {
        "id": "d7NBiSr-R4BD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.bos_token = tokenizer.cls_token\n",
        "tokenizer.eos_token = tokenizer.sep_token"
      ],
      "metadata": {
        "id": "cibGEcPNR7CM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.bos_token = 2\n",
        "tokenizer.eos_token = 3"
      ],
      "metadata": {
        "id": "fOz_8duDR9hV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(['Unnamed: 0'],axis=1,inplace=True)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "OuIhI_mVR_jO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "EMgEHKu4SBY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split, RandomSampler, SequentialSampler\n",
        "torch.manual_seed(42)\n",
        "import random\n",
        "\n",
        "from transformers import GPT2LMHeadModel, GPT2Config\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup"
      ],
      "metadata": {
        "id": "VasafWOBSEM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = EncoderDecoderModel.from_pretrained(\"/bertshared-kor-base\")"
      ],
      "metadata": {
        "id": "DCeltXxPSE7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch.utils.data as data_utils"
      ],
      "metadata": {
        "id": "PAbCqLfXSIT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datasets"
      ],
      "metadata": {
        "id": "F9rOOB6YSS9f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "passage = []\n",
        "summary = []\n",
        "for i in range(4000):\n",
        "  passage.append(df['passage'][i])\n",
        "  summary.append(df['summary'][i])\n",
        "\n",
        "train_dict = {'passage':passage, 'summary':summary}\n",
        "\n",
        "train_set = datasets.Dataset.from_dict(train_dict)"
      ],
      "metadata": {
        "id": "JA-SN1U1ST_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=4  # change to 16 for full training\n",
        "encoder_max_length=512\n",
        "decoder_max_length=128\n",
        "\n",
        "def process_data_to_model_inputs(batch):\n",
        "  # tokenize the inputs and labels\n",
        "  inputs = tokenizer(batch[\"passage\"], padding=\"max_length\", truncation=True, max_length=encoder_max_length)\n",
        "  outputs = tokenizer(batch[\"summary\"], padding=\"max_length\", truncation=True, max_length=decoder_max_length)\n",
        "\n",
        "  batch[\"input_ids\"] = inputs.input_ids\n",
        "  batch[\"attention_mask\"] = inputs.attention_mask\n",
        "  batch[\"decoder_input_ids\"] = outputs.input_ids\n",
        "  batch[\"decoder_attention_mask\"] = outputs.attention_mask\n",
        "  batch[\"labels\"] = outputs.input_ids.copy()\n",
        "\n",
        "  # because BERT automatically shifts the labels, the labels correspond exactly to `decoder_input_ids`. \n",
        "  # We have to make sure that the PAD token is ignored\n",
        "  batch[\"labels\"] = [[-100 if token == tokenizer.pad_token_id else token for token in labels] for labels in batch[\"labels\"]]\n",
        "\n",
        "  return batch\n",
        "\n",
        "# only use 32 training examples for notebook - DELETE LINE FOR FULL TRAINING\n",
        "#train_data = train_data.select(range(32))\n",
        "\n",
        "train_data = train_set.map(\n",
        "    process_data_to_model_inputs, \n",
        "    batched=True, \n",
        "    batch_size=batch_size, \n",
        "    remove_columns=[\"passage\", \"summary\"]\n",
        ")\n",
        "train_data.set_format(\n",
        "    type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"decoder_input_ids\", \"decoder_attention_mask\", \"labels\"],\n",
        ")\n",
        "\n",
        "\n",
        "# only use 16 training examples for notebook - DELETE LINE FOR FULL TRAINING\n",
        "#val_data = val_set.select(range(16))\n",
        "\n",
        "val_data = val_set.map(\n",
        "    process_data_to_model_inputs, \n",
        "    batched=True, \n",
        "    batch_size=batch_size, \n",
        "    remove_columns=[\"passage\", \"summary\"]\n",
        ")\n",
        "val_data.set_format(\n",
        "    type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"decoder_input_ids\", \"decoder_attention_mask\", \"labels\"],\n",
        ")"
      ],
      "metadata": {
        "id": "00oV7LxOSWCg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[4]"
      ],
      "metadata": {
        "id": "yceSKElES-Bl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Finetuning"
      ],
      "metadata": {
        "id": "ZhwpqpgGTA5M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.config.max_length = 512\n",
        "model.config.min_length = 128"
      ],
      "metadata": {
        "id": "1KJaYEe6S_HD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set special tokens\n",
        "model.config.decoder_start_token_id = tokenizer.bos_token_id\n",
        "model.config.eos_token_id = tokenizer.eos_token_id\n",
        "model.config.pad_token_id = 0 #tokenizer.pad_token_id\n",
        "\n",
        "# sensible parameters for beam search\n",
        "model.config.vocab_size = 42000 #model.config.decoder.vocab_size\n",
        "model.config.max_length = 40\n",
        "model.config.min_length = 0\n",
        "model.config.no_repeat_ngram_size = 0\n",
        "model.config.early_stopping = False\n",
        "model.config.length_penalty = 1.0\n",
        "model.config.num_beams = 1"
      ],
      "metadata": {
        "id": "G4psrC9NTD5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.config.vocab_size = 42000 #model.config.decoder.vocab_size\n",
        "model.config.max_length = 100\n",
        "model.config.min_length = 10"
      ],
      "metadata": {
        "id": "_lNDvqJZTFfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer"
      ],
      "metadata": {
        "id": "TNPhPw_gTGd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, load_metric"
      ],
      "metadata": {
        "id": "MZv_T8AfTI8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install rouge_score"
      ],
      "metadata": {
        "id": "4KGlkorGTJ_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load rouge for validation\n",
        "rouge = datasets.load_metric(\"rouge\")\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels_ids = pred.label_ids\n",
        "    pred_ids = pred.predictions\n",
        "\n",
        "    # all unnecessary tokens are removed\n",
        "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
        "    labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n",
        "    label_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n",
        "\n",
        "    rouge_output = rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rouge2\"])[\"rouge2\"].mid\n",
        "\n",
        "    return {\n",
        "        \"rouge2_precision\": round(rouge_output.precision, 4),\n",
        "        \"rouge2_recall\": round(rouge_output.recall, 4),\n",
        "        \"rouge2_fmeasure\": round(rouge_output.fmeasure, 4),\n",
        "    }"
      ],
      "metadata": {
        "id": "d1JqMTnuTLKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(\"cuda\")"
      ],
      "metadata": {
        "id": "HvEUOvstTN2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set training arguments - these params are not really tuned, feel free to change\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./\",\n",
        "    evaluation_strategy=\"steps\",\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    predict_with_generate=True,\n",
        "    logging_steps=2,  # set to 1000 for full training\n",
        "    save_steps=8,  # set to 500 for full training\n",
        "    eval_steps=4,  # set to 8000 for full training\n",
        "    warmup_steps=1,  # set to 2000 for full training\n",
        "    max_steps=16, # delete for full training\n",
        "    overwrite_output_dir=True,\n",
        "    save_total_limit=3,\n",
        "    #fp16=True, \n",
        ")\n",
        "\n",
        "# instantiate trainer\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_args,\n",
        "    compute_metrics=compute_metrics,\n",
        "    train_dataset=train_data,\n",
        "    eval_dataset=val_data,\n",
        ")\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "gWpb6rwuTR4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "/content/checkpoint-16"
      ],
      "metadata": {
        "id": "7j3f7tUhT_PV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, '/content/drive/MyDrive/model3.pt')"
      ],
      "metadata": {
        "id": "f9Uvv021TWr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model = torch.load('/content/drive/MyDrive/model3.pt') "
      ],
      "metadata": {
        "id": "83QtRhHbTXfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = '''\n",
        "LG전자가 스마트폰을 담당하는 MC(모바일커뮤니케이션)사업부 분할 및 매각을 위한 법률 자문 업무를 김앤장법률사무소에 맡겼다. MC사업부 매각 작업에 속도가 붙을지 관심이 집중되고 있다.\n",
        "22일 인수합병(M&A)업계에 따르면 LG전자는 최근 MC사업부 분할 후 매각 방안 등을 포괄적으로 검토하기 위해 김앤장을 법률자문사로 선임한 것으로 알려졌다. 회계·실사 자문은 EY한영회계법인에 맡길 가능성이 큰 것으로 전해졌다. 김앤장 등 자문사들은 사업본부를 분할한 뒤 사업양수도나 분할사업부의 지분 매각, 지식재산권(IP) 매각 등을 놓고 검토에 들어간 것으로 알려졌다.\n",
        "업계에서는 LG전자가 MC사업본부를 통매각하기보다는 ‘쪼개기 매각’에 나설 것으로 보고 있다. 스마트폰 선행기술 연구개발(R&D) 등 핵심 기능만 남겨둔 채 매각을 시도할 것으로 관측하고 있다. 앞서 권봉석 LG전자 사장은 사내 메시지를 통해 임직원에게 “현재 모든 가능성을 열어 두고 사업 운영방향을 면밀히 검토하고 있다”고 밝히며 매각 추진을 암시했다. M&A업계 관계자는 “거래가 성사되기도 전에 사업 전면 재검토를 공식화한 것은 상당히 이례적”이라며 “향후 매각이 잘 이뤄지지 않더라도 모바일 사업을 철수하겠다는 배수진을 둔 것으로 보인다”고 설명했다.\n",
        "다만 원매자를 찾기가 쉽지 않을 것이란 전망이 우세하다. LG전자 모바일 사업은 한때 글로벌시장에서 톱5 안에 드는 기술력을 인정받았지만 누적 적자만 5조원에 달하고 있다. 업계에서 평가하는 MC사업부의 가치도 5000억원대에서 수조원대까지 편차가 상당히 크다.\n",
        "상대적으로 해외 원매자들의 인수의사가 더 확실한 것으로 알려지고 있다. 북미사업 등 글로벌 시장 확장을 원하는 후발기업들이 주요 대상이다. 베트남의 빈그룹과 중국 기업 등이 유력하게 거론된다. 증권업계를 중심으로는 스마트 기기를 연결하는 사물인터넷(IoT) 사업을 염두에 둔 구글, 페이스북 같은 미국 정보기술(IT) 기업들도 원매자 후보군으로 꼽고 있다.\n",
        "'''"
      ],
      "metadata": {
        "id": "4afa3OzOTXYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model.to(\"cuda\")"
      ],
      "metadata": {
        "id": "0WLmDKLNTXRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = tokenizer.encode(text, return_tensors= 'pt').to(\"cuda\")\n",
        "\n",
        "sentence_length = len(input_ids[0])\n",
        "min_length = max(10, int(0.1*sentence_length))\n",
        "max_length = min(128, int(0.3*sentence_length))\n",
        "\n",
        "outputs = trained_model.generate(\n",
        "            input_ids,\n",
        "            min_length=min_length,\n",
        "            max_length=max_length\n",
        "        ).to(\"cuda\")\n",
        "\n",
        "\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "_umgRt34TXGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = pd.read_csv(\"/content/drive/MyDrive/test.csv\")\n",
        "\n",
        "df2.drop(['Unnamed: 0'],axis=1,inplace=True)\n",
        "passage = []\n",
        "summary = []\n",
        "for i in range(len(df2)):\n",
        "  passage.append(df2['passage'][i])\n",
        "  summary.append(df2['summary'][i])\n",
        "\n",
        "test_dict = {'passage':passage, 'summary':summary}\n",
        "\n",
        "test_set = datasets.Dataset.from_dict(test_dict)"
      ],
      "metadata": {
        "id": "nxR64vPKTj7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "qhyYRP5BTj5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datasets\n",
        "from transformers import BertTokenizer, EncoderDecoderModel\n",
        "\n",
        "tokenizer =BertTokenizerFast.from_pretrained(\"/bertshared-kor-base\")\n",
        "model = EncoderDecoderModel.from_pretrained(\"./checkpoint-16\")\n",
        "model.to(\"cuda\")\n",
        "\n",
        "\n",
        "\n",
        "batch_size = 2 \n",
        "\n",
        "\n",
        "def generate_summary(batch):\n",
        "    # cut off at BERT max length 512\n",
        "    inputs = tokenizer(batch[\"article\"], padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\")\n",
        "    input_ids = inputs.input_ids.to(\"cuda\")\n",
        "    attention_mask = inputs.attention_mask.to(\"cuda\")\n",
        "\n",
        "    outputs = model.generate(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "    output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "\n",
        "    batch[\"pred_summary\"] = output_str\n",
        "\n",
        "    return batch"
      ],
      "metadata": {
        "id": "nd-TseMdTj3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datasets\n",
        "from transformers import BertTokenizer, EncoderDecoderModel\n",
        "\n",
        "tokenizer =BertTokenizerFast.from_pretrained(\"kykim/bertshared-kor-base\")\n",
        "model = EncoderDecoderModel.from_pretrained(\"./checkpoint-16\")\n",
        "model.to(\"cuda\")\n",
        "\n",
        "batch_size = 2  # change to 64 for full evaluation"
      ],
      "metadata": {
        "id": "vxdMgB17Tj0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = '''\n",
        "현대자동차가 미국 '인플레이션 감축법' 대응 방안으로 미국 조지아주에 설립키로 한 전기차 전용공장의 착공 시점을 앞당기기로 했다. 또 전기차 보조금만큼의 가격 할인도 검토 중이다.\n",
        "23일 완성차 업계에 따르면 현대차는 당초 내년 상반기 착공 예정이었던 조지아주 전기차 전용공장 설립을 올해 안에 시작하기로 했다.\n",
        "현대차가 올해 공사를 시작하면 2024년 하반기엔 공장을 완성할 수 있다.\n",
        "이 같은 결정은 인플레이션 감축법으로 인해 받지 못하는 전기차 보조금 때문에 시장점유율 이탈을 우려한 때문이다.\n",
        "현대차그룹은 현재 미국 시장에서 아이오닉5, 코나EV, 제네시스 GV60, EV6, 니로EV 등 5개 모델를 판매 중이다.\n",
        "현대차는 미국 내 전기차 조립 라인이 없어 5개 모델 모두를 국내에서 생산해 수출하고 있다.\n",
        "현대차는 GV70 전기차와 EV9 등 일부 차종은 기존 미국 생산 라인을 전환해 현지 생산할 계획이지만, 주력 차종인 아이오닉5 등은 여전히 국내에서 만들어 미국으로 보내야 하는 상황이다.\n",
        "정부의 전기차 보조금 지급 대상에서 제외된다. 현대차가 조금씩 넓히고 있는 전기차 시장에 빨간불이 켜진 셈이다.\n",
        "현대차는 올해 상반기 미국 시장 전기차 점유율에서 테슬라(70%)에 이어 2위(9%)를 차지했다.\n",
        "현대차는 비록 2위지만 올해 들어 지난달까지 약 4만대의 전기차를 미국에 수출하는 등 미국 포드와 독일 폭스바겐을 제치며 성장 중이었다.\n",
        "하지만 보조금을 받지 못해 가격이 오르면 경쟁력에서 밀리고 결국 시장 선점에 어려움을 겪을 수 있다.\n",
        "실제로 아이오닉 5의 가격은 보조금 7500달러(약 1000만원)을 제외하면 4만 달러(약 5250만원) 수준이다.\n",
        "비슷한 성능인 포드의 머스탱 마하E는 4만4000달러(5800만원)로 아이오닉 5보다 500만원가량 비쌌다. 하지만 보조금을 받지 못하면 포드 머스탱 마하E가 아이오닉 5보다 450만원 정도 가격이 낮아진다.\n",
        "이에 따라 현대차그룹은 이번 인플레이션 감축법 문제로 조지아주 공장 설립 시기를 앞당기고 또 한편으로는 일정기간 가격 할인 등의 프로모션(판촉활동)도 검토 중인 것으로 알려졌다.\n",
        "현대차에서 소비자들에게 가격을 보전해준다면 수익성은 줄어들겠지만 시장점유율은 확보할 수 있다. 전기차 시장에선 점유율이 중요한 만큼 현대차의 고심이 깊어지는 것이다.\n",
        "완성차업계 관계자는 \"연내 조지아주 공장 착공을 목표로 알고 있다\"며 \"그 외에도 여러가지 방법을 검토 중\"이라고 했다.\n",
        "한편 조 바이든 미국 대통령이 서명해 시행된 인플레이션 감축법은 북미에서 최종 조립되는 전기차만 보조금을 받을 수 있도록 하고 있다. 이 법으로 인해 전기차 보조금 지급 대상이 기존 72개 모델에서 21개로 축소됐다.\n",
        "지급 대상 차종은 아우디 Q5, BMW X5와 3시리즈 플러그인, 포드Mach-E, F 시리즈, 에스케이프 PHEV와 Transit 밴, 크라이슬러 Pacifica PHEV, 지프 그랜드 체로키 PHEV, 랭글러 PHEV, 링컨 에비에이터 PHEV, 코세어 플러그인, 루시드 에어, 닛산 리프, 볼보 S60, 리비안 R1S와 R1T 등이다. 테슬라와 GM 전기차도 받는다.\n",
        "반면 현대차그룹, 포르쉐 등이 판매하는 전기차는 보조금을 받을 수 없게 된다.\n",
        "'''"
      ],
      "metadata": {
        "id": "7K2CNmPPTjyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_summary(test_set[10])"
      ],
      "metadata": {
        "id": "L20XBtL8Tjs2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_length"
      ],
      "metadata": {
        "id": "nDGXk9vrUWVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = tokenizer.encode(text, return_tensors= 'pt',padding=\"max_length\",truncation=True, max_length = encoder_max_length)\n",
        "\n",
        "sentence_length = len(input_ids[0])\n",
        "min_length = max(10, int(0.1*sentence_length))\n",
        "max_length = min(128, int(0.3*sentence_length))\n",
        "\n",
        "\n",
        "outputs = model.generate(\n",
        "            input_ids,\n",
        "            min_length=min_length,\n",
        "            max_length=max_length\n",
        "        )\n",
        "\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "ynWodNCQUYS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, '/content/drive/MyDrive/model2.pt')"
      ],
      "metadata": {
        "id": "0gjEGN80UZXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "/content/checkpoint-16\n",
        "/content/runs"
      ],
      "metadata": {
        "id": "3e9QWXf3UaGy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}